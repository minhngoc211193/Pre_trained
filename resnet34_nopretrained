{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1351797,"sourceType":"datasetVersion","datasetId":786787}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/minnievu/resnet34?scriptVersionId=197971103\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"!pip install torchsummary\n","metadata":{"execution":{"iopub.status.busy":"2024-09-23T16:45:10.271662Z","iopub.execute_input":"2024-09-23T16:45:10.272534Z","iopub.status.idle":"2024-09-23T16:45:22.937651Z","shell.execute_reply.started":"2024-09-23T16:45:10.272491Z","shell.execute_reply":"2024-09-23T16:45:22.93669Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchsummary in /opt/conda/lib/python3.10/site-packages (1.5.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch, torchvision\nfrom torchvision import datasets, models, transforms\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\n\nimport time\nfrom torchsummary import summary\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\n\nfrom PIL import Image\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import Dense, Input, Dropout\nfrom tensorflow.keras.losses import categorical_crossentropy\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau","metadata":{"execution":{"iopub.status.busy":"2024-09-23T16:45:52.577525Z","iopub.execute_input":"2024-09-23T16:45:52.577959Z","iopub.status.idle":"2024-09-23T16:45:58.660702Z","shell.execute_reply.started":"2024-09-23T16:45:52.577917Z","shell.execute_reply":"2024-09-23T16:45:58.659901Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os\n# Define data transformations\nPATH = \"/kaggle/input/fer2013\"\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n        transforms.RandomRotation(degrees=15),\n        transforms.RandomHorizontalFlip(),\n        transforms.CenterCrop(size=224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225])\n    ]),\n    'test': transforms.Compose([\n        transforms.Resize(size=256),\n        transforms.CenterCrop(size=224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225])\n    ]),\n}\n\n\n\n# Load dataset\ntrain_dir = os.path.join(PATH, 'train')\ntest_dir = os.path.join(PATH, 'test')\n\ntrain_data = datasets.ImageFolder(train_dir, transform=data_transforms['train'])\ntest_data = datasets.ImageFolder(test_dir, transform=data_transforms['test'])\n\ntrain_data_loader = DataLoader(train_data, batch_size=128, shuffle=True)\ntest_data_loader = DataLoader(test_data, batch_size=128, shuffle=True)\n\n\ntrain_data_size = len(train_data)\ntest_data_size = len(test_data)\n\n\n\n# Determine device to run on\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-09-23T16:46:02.605083Z","iopub.execute_input":"2024-09-23T16:46:02.606064Z","iopub.status.idle":"2024-09-23T16:46:09.481642Z","shell.execute_reply.started":"2024-09-23T16:46:02.606014Z","shell.execute_reply":"2024-09-23T16:46:09.480595Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Tải mô hình ResNet-34 chưa huấn luyện \nresnet34 = models.resnet34(weights = None)\nresnet34 = resnet34.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-09-23T16:46:13.336442Z","iopub.execute_input":"2024-09-23T16:46:13.33736Z","iopub.status.idle":"2024-09-23T16:46:13.843611Z","shell.execute_reply.started":"2024-09-23T16:46:13.337304Z","shell.execute_reply":"2024-09-23T16:46:13.842795Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"loss_func = nn.CrossEntropyLoss()\n\ndef train_model(model, loss_criterion, optimizer, scheduler,epochs=25):\n    '''\n    Function to train and validate\n    Parameters\n        :param model: Model to train and validate\n        :param loss_criterion: Loss Criterion to minimize\n        :param optimizer: Optimizer for computing gradients\n        :param epochs: Number of epochs (default=25)\n\n    Returns\n        model: Trained Model with best validation accuracy\n        history: (dict object): Having training loss, accuracy and validation loss, accuracy\n    '''\n\n    start = time.time()\n    history = []\n    best_loss = 100000.0\n    best_epoch = None\n\n    for epoch in range(epochs):\n        epoch_start = time.time()\n        print(\"Epoch: {}/{}\".format(epoch+1, epochs))\n\n        # Set to training mode\n        model.train()\n\n        # Loss and Accuracy within the epoch\n        train_loss = 0.0\n        train_acc = 0.0\n\n        valid_loss = 0.0\n        valid_acc = 0.0\n\n        for i, (inputs, labels) in enumerate(train_data_loader):\n\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            # Clean existing gradients\n            optimizer.zero_grad()\n\n            # Forward pass - compute outputs on input data using the model\n            outputs = model(inputs)\n\n            # Compute loss\n            loss = loss_criterion(outputs, labels)\n\n            # Backpropagate the gradients\n            loss.backward()\n\n            # Update the parameters\n            optimizer.step()\n            scheduler.step()\n\n            # Compute the total loss for the batch and add it to train_loss\n            train_loss += loss.item() * inputs.size(0)\n\n            # Compute the accuracy\n            ret, predictions = torch.max(outputs.data, 1)\n            correct_counts = predictions.eq(labels.data.view_as(predictions))\n\n            # Convert correct_counts to float and then compute the mean\n            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n\n            # Compute total accuracy in the whole batch and add to train_acc\n            train_acc += acc.item() * inputs.size(0)\n\n            #print(\"Batch number: {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}\".format(i, loss.item(), acc.item()))\n\n\n        # Validation - No gradient tracking needed\n        with torch.no_grad():\n\n            # Set to evaluation mode\n            model.eval()\n\n            # Validation loop\n            for j, (inputs, labels) in enumerate(test_data_loader):\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # Forward pass - compute outputs on input data using the model\n                outputs = model(inputs)\n\n                # Compute loss\n                loss = loss_criterion(outputs, labels)\n\n                # Compute the total loss for the batch and add it to valid_loss\n                valid_loss += loss.item() * inputs.size(0)\n\n                # Calculate validation accuracy\n                ret, predictions = torch.max(outputs.data, 1)\n                correct_counts = predictions.eq(labels.data.view_as(predictions))\n\n                # Convert correct_counts to float and then compute the mean\n                acc = torch.mean(correct_counts.type(torch.FloatTensor))\n\n                # Compute total accuracy in the whole batch and add to valid_acc\n                valid_acc += acc.item() * inputs.size(0)\n                if not j%100:\n                  print(\"Validation Batch number: {:03d}, Validation: Loss: {:.4f}, Accuracy: {:.4f}\".format(j, loss.item(), acc.item()))\n        if valid_loss < best_loss:\n            best_loss = valid_loss\n            best_epoch = epoch\n\n        # Find average training loss and training accuracy\n        avg_train_loss = train_loss/train_data_size\n        avg_train_acc = train_acc/train_data_size\n\n        # Find average training loss and training accuracy\n        avg_valid_loss = valid_loss/test_data_size\n        avg_valid_acc = valid_acc/test_data_size\n\n        history.append([avg_train_loss, avg_valid_loss, avg_train_acc, avg_valid_acc])\n\n        epoch_end = time.time()\n\n        print(\"Epoch : {:03d}, Training: Loss - {:.4f}, Accuracy - {:.4f}%, \\n\\t\\tValidation : Loss - {:.4f}, Accuracy - {:.4f}%, Time: {:.4f}s\".format(epoch+1, avg_train_loss, avg_train_acc*100, avg_valid_loss, avg_valid_acc*100, epoch_end-epoch_start))\n\n        # Save if the model has best accuracy till now\n        torch.save(model, 'model_'+str(epoch)+'.pt')\n\n    return model, history, best_epoch\n\n# train model\nnum_epochs = 25\noptimizer = optim.Adam(resnet34.parameters(), lr=0.001)\nscheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10,20], gamma=0.1)\ntrained_model, history, best_epoch = train_model(resnet34, loss_func, optimizer, scheduler, num_epochs)\ntorch.save(history, 'history.pt')","metadata":{"execution":{"iopub.status.busy":"2024-09-23T16:46:17.165529Z","iopub.execute_input":"2024-09-23T16:46:17.166261Z","iopub.status.idle":"2024-09-23T18:03:54.846313Z","shell.execute_reply.started":"2024-09-23T16:46:17.166222Z","shell.execute_reply":"2024-09-23T18:03:54.8452Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Epoch: 1/25\nValidation Batch number: 000, Validation: Loss: 1.7410, Accuracy: 0.2578\nEpoch : 001, Training: Loss - 1.8261, Accuracy - 26.9219%, \n\t\tValidation : Loss - 1.7204, Accuracy - 31.2761%, Time: 188.9364s\nEpoch: 2/25\nValidation Batch number: 000, Validation: Loss: 1.5344, Accuracy: 0.3828\nEpoch : 002, Training: Loss - 1.6470, Accuracy - 35.0413%, \n\t\tValidation : Loss - 1.6070, Accuracy - 37.5313%, Time: 182.9957s\nEpoch: 3/25\nValidation Batch number: 000, Validation: Loss: 1.5641, Accuracy: 0.4062\nEpoch : 003, Training: Loss - 1.5665, Accuracy - 39.1445%, \n\t\tValidation : Loss - 1.5186, Accuracy - 41.7247%, Time: 184.3929s\nEpoch: 4/25\nValidation Batch number: 000, Validation: Loss: 1.5302, Accuracy: 0.4375\nEpoch : 004, Training: Loss - 1.5057, Accuracy - 41.6977%, \n\t\tValidation : Loss - 1.4697, Accuracy - 43.4522%, Time: 184.7844s\nEpoch: 5/25\nValidation Batch number: 000, Validation: Loss: 1.3975, Accuracy: 0.4766\nEpoch : 005, Training: Loss - 1.4569, Accuracy - 43.8120%, \n\t\tValidation : Loss - 1.4041, Accuracy - 46.3918%, Time: 183.3300s\nEpoch: 6/25\nValidation Batch number: 000, Validation: Loss: 1.3017, Accuracy: 0.5234\nEpoch : 006, Training: Loss - 1.4203, Accuracy - 45.3865%, \n\t\tValidation : Loss - 1.3794, Accuracy - 47.2276%, Time: 186.2534s\nEpoch: 7/25\nValidation Batch number: 000, Validation: Loss: 1.3199, Accuracy: 0.4922\nEpoch : 007, Training: Loss - 1.3834, Accuracy - 46.9748%, \n\t\tValidation : Loss - 1.3409, Accuracy - 48.4954%, Time: 199.7981s\nEpoch: 8/25\nValidation Batch number: 000, Validation: Loss: 1.2722, Accuracy: 0.4766\nEpoch : 008, Training: Loss - 1.3494, Accuracy - 48.0964%, \n\t\tValidation : Loss - 1.3297, Accuracy - 49.8328%, Time: 192.8423s\nEpoch: 9/25\nValidation Batch number: 000, Validation: Loss: 1.2270, Accuracy: 0.5469\nEpoch : 009, Training: Loss - 1.3273, Accuracy - 49.2563%, \n\t\tValidation : Loss - 1.2962, Accuracy - 50.4876%, Time: 190.2777s\nEpoch: 10/25\nValidation Batch number: 000, Validation: Loss: 1.1665, Accuracy: 0.6016\nEpoch : 010, Training: Loss - 1.3033, Accuracy - 50.1341%, \n\t\tValidation : Loss - 1.2809, Accuracy - 51.6578%, Time: 186.4072s\nEpoch: 11/25\nValidation Batch number: 000, Validation: Loss: 1.3163, Accuracy: 0.5156\nEpoch : 011, Training: Loss - 1.2756, Accuracy - 51.3393%, \n\t\tValidation : Loss - 1.2672, Accuracy - 52.1315%, Time: 188.4573s\nEpoch: 12/25\nValidation Batch number: 000, Validation: Loss: 1.2159, Accuracy: 0.5547\nEpoch : 012, Training: Loss - 1.2551, Accuracy - 52.2136%, \n\t\tValidation : Loss - 1.2519, Accuracy - 52.7445%, Time: 184.9414s\nEpoch: 13/25\nValidation Batch number: 000, Validation: Loss: 1.2532, Accuracy: 0.5312\nEpoch : 013, Training: Loss - 1.2357, Accuracy - 53.1854%, \n\t\tValidation : Loss - 1.2385, Accuracy - 52.7724%, Time: 184.3863s\nEpoch: 14/25\nValidation Batch number: 000, Validation: Loss: 1.1023, Accuracy: 0.5859\nEpoch : 014, Training: Loss - 1.2238, Accuracy - 53.4919%, \n\t\tValidation : Loss - 1.2290, Accuracy - 53.1903%, Time: 185.9877s\nEpoch: 15/25\nValidation Batch number: 000, Validation: Loss: 1.2585, Accuracy: 0.5391\nEpoch : 015, Training: Loss - 1.2022, Accuracy - 54.3941%, \n\t\tValidation : Loss - 1.2125, Accuracy - 54.4023%, Time: 183.8400s\nEpoch: 16/25\nValidation Batch number: 000, Validation: Loss: 1.3412, Accuracy: 0.5000\nEpoch : 016, Training: Loss - 1.1945, Accuracy - 54.5230%, \n\t\tValidation : Loss - 1.2099, Accuracy - 53.5943%, Time: 182.0096s\nEpoch: 17/25\nValidation Batch number: 000, Validation: Loss: 1.2617, Accuracy: 0.5234\nEpoch : 017, Training: Loss - 1.1777, Accuracy - 55.2823%, \n\t\tValidation : Loss - 1.1948, Accuracy - 54.6810%, Time: 182.2771s\nEpoch: 18/25\nValidation Batch number: 000, Validation: Loss: 1.1267, Accuracy: 0.5391\nEpoch : 018, Training: Loss - 1.1640, Accuracy - 55.8048%, \n\t\tValidation : Loss - 1.1833, Accuracy - 55.7816%, Time: 182.2231s\nEpoch: 19/25\nValidation Batch number: 000, Validation: Loss: 1.0565, Accuracy: 0.6250\nEpoch : 019, Training: Loss - 1.1530, Accuracy - 56.2054%, \n\t\tValidation : Loss - 1.1973, Accuracy - 54.9039%, Time: 185.4082s\nEpoch: 20/25\nValidation Batch number: 000, Validation: Loss: 1.1883, Accuracy: 0.5078\nEpoch : 020, Training: Loss - 1.1393, Accuracy - 56.9473%, \n\t\tValidation : Loss - 1.1710, Accuracy - 55.8930%, Time: 184.9419s\nEpoch: 21/25\nValidation Batch number: 000, Validation: Loss: 1.1531, Accuracy: 0.5391\nEpoch : 021, Training: Loss - 1.1295, Accuracy - 57.1249%, \n\t\tValidation : Loss - 1.1639, Accuracy - 56.3527%, Time: 187.8018s\nEpoch: 22/25\nValidation Batch number: 000, Validation: Loss: 1.1009, Accuracy: 0.5859\nEpoch : 022, Training: Loss - 1.1144, Accuracy - 58.1560%, \n\t\tValidation : Loss - 1.1604, Accuracy - 55.9487%, Time: 185.5772s\nEpoch: 23/25\nValidation Batch number: 000, Validation: Loss: 1.1804, Accuracy: 0.5625\nEpoch : 023, Training: Loss - 1.1087, Accuracy - 58.0306%, \n\t\tValidation : Loss - 1.1568, Accuracy - 56.3527%, Time: 185.7657s\nEpoch: 24/25\nValidation Batch number: 000, Validation: Loss: 1.0413, Accuracy: 0.6250\nEpoch : 024, Training: Loss - 1.0874, Accuracy - 58.8004%, \n\t\tValidation : Loss - 1.1498, Accuracy - 57.0772%, Time: 184.8100s\nEpoch: 25/25\nValidation Batch number: 000, Validation: Loss: 1.1912, Accuracy: 0.4844\nEpoch : 025, Training: Loss - 1.0842, Accuracy - 58.9571%, \n\t\tValidation : Loss - 1.1539, Accuracy - 56.6453%, Time: 184.9731s\n","output_type":"stream"}]}]}